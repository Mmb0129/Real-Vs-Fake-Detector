{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8712977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage import feature, io\n",
    "from skimage.transform import resize\n",
    "from skimage.util import img_as_ubyte\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from fuzzywuzzy import fuzz, process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43e1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------- Feature Extraction ---------------------\n",
    "class FeatureExtraction():\n",
    "    def __init__(self):\n",
    "        self.image_size = (240, 240)\n",
    "\n",
    "    def extract_labels(self):\n",
    "        paths = []\n",
    "        non_valid_files = ['810199515_real_none_jungle_10', '810199515_real_none_jungle_1', 'desktop.ini', '810100473_real_none_sea_4']\n",
    "        for image_path in os.listdir(self.image_dir):\n",
    "            if not any(nvf in image_path for nvf in non_valid_files):\n",
    "                paths.append(image_path)\n",
    "        return pd.DataFrame({0: paths})\n",
    "\n",
    "    def lbp(self, path):\n",
    "        try:\n",
    "            img = io.imread(os.path.join(self.image_dir, path))\n",
    "            if img.ndim == 3:\n",
    "                from skimage.color import rgb2gray\n",
    "                img = rgb2gray(img)\n",
    "            img = resize(img, self.image_size)\n",
    "            img = img_as_ubyte(img)\n",
    "            lbp = feature.local_binary_pattern(img, 8, 1, method='uniform')\n",
    "            hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 59))\n",
    "            return hist\n",
    "        except:\n",
    "            return np.zeros(58)\n",
    "\n",
    "    def fft(self, path):\n",
    "        try:\n",
    "            img = io.imread(os.path.join(self.image_dir, path))\n",
    "            if img.ndim == 3:\n",
    "                from skimage.color import rgb2gray\n",
    "                img = rgb2gray(img)\n",
    "            img = resize(img, self.image_size)\n",
    "            fft_img = np.fft.fft2(img)\n",
    "            fft_shift = np.fft.fftshift(fft_img)\n",
    "            magnitude = np.log(1 + np.abs(fft_shift))\n",
    "            return magnitude.flatten()\n",
    "        except:\n",
    "            return np.zeros(self.image_size[0]*self.image_size[1])\n",
    "\n",
    "    def extract(self):\n",
    "        self.df = self.extract_labels()\n",
    "        tqdm.pandas()\n",
    "        self.df['lbp'] = self.df[0].progress_apply(self.lbp)\n",
    "        self.df['fft'] = self.df[0].progress_apply(self.fft)\n",
    "        lbp_df = pd.DataFrame(self.df['lbp'].tolist())\n",
    "        fft_df = pd.DataFrame(self.df['fft'].tolist())\n",
    "        return self.df, pd.concat([lbp_df, fft_df], axis=1)\n",
    "\n",
    "    def pca(self, features_df):\n",
    "        scaled = StandardScaler().fit_transform(features_df)\n",
    "        reduced = PCA(n_components=512).fit_transform(scaled)\n",
    "        return pd.DataFrame(reduced)\n",
    "\n",
    "    def run(self, real_dir, fake_dir):\n",
    "        self.image_dir = real_dir\n",
    "        real_labels, real_features = self.extract()\n",
    "\n",
    "        self.image_dir = fake_dir\n",
    "        fake_labels, fake_features = self.extract()\n",
    "\n",
    "        features = pd.concat([real_features, fake_features], axis=0)\n",
    "        labels = pd.concat([real_labels, fake_labels], axis=0)\n",
    "        return self.pca(features), labels.drop(['lbp', 'fft'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1550b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------- Preprocessing ---------------------\n",
    "class Preprocessing():\n",
    "    def __init__(self, features_file, labels_file):\n",
    "        self.features_df = features_file\n",
    "        self.labels_df = labels_file[0].str.replace('-', '_').str.split('_', expand=True)\n",
    "        self.labels_df = self.labels_df.drop([0, 4], axis=1)\n",
    "        self.labels_df.columns = [\"class\", \"generator\", \"category\"]\n",
    "\n",
    "    def fix_category_names(self):\n",
    "        self.labels_df[\"category\"] = self.labels_df[\"category\"].replace({\"forest\": \"jungle\"})\n",
    "        valid = ['sea', 'mountain', 'jungle']\n",
    "        self.labels_df[\"category\"] = self.labels_df[\"category\"].apply(lambda x: process.extractOne(x.lower(), valid, scorer=fuzz.token_set_ratio)[0])\n",
    "\n",
    "    def fix_class_names(self):\n",
    "        self.labels_df[\"class\"] = self.labels_df[\"class\"].str.lower()\n",
    "\n",
    "    def fix_generator_names(self):\n",
    "        valid = [\"none\", \"stable\", \"dalle\", \"dream\", \"midjourney\", \"craiyon\"]\n",
    "        self.labels_df[\"generator\"] = self.labels_df[\"generator\"].apply(lambda x: process.extractOne(x.lower(), valid, scorer=fuzz.token_set_ratio)[0])\n",
    "\n",
    "    def normalize(self):\n",
    "        self.features_df = pd.DataFrame(StandardScaler().fit_transform(self.features_df))\n",
    "\n",
    "    def preprocess(self):\n",
    "        self.fix_category_names()\n",
    "        self.fix_generator_names()\n",
    "        self.fix_class_names()\n",
    "        self.normalize()\n",
    "\n",
    "    def get_dataframes(self):\n",
    "        return self.labels_df, self.features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "042cb23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1707/1707 [45:50<00:00,  1.61s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1707/1707 [31:27<00:00,  1.11s/it]\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████▎| 1696/1710 [03:05<00:02,  6.34it/s]C:\\Users\\nandh\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1710/1710 [03:06<00:00,  9.16it/s]\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████▎| 1696/1710 [02:44<00:01,  7.82it/s]C:\\Users\\nandh\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1710/1710 [02:45<00:00, 10.33it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------- Pipeline ---------------------\n",
    "\n",
    "# Update your real and fake image directory paths\n",
    "real_dir = r\"C:\\Desktop\\MLAssignment\\real\"\n",
    "fake_dir = r\"C:\\Desktop\\MLAssignment\\fake\"\n",
    "\n",
    "# Step 1: Extract handcrafted features (LBP + FFT)\n",
    "feature_extraction = FeatureExtraction()\n",
    "h_features, h_labels = feature_extraction.run(real_dir, fake_dir)\n",
    "\n",
    "# Step 2: Preprocess features and labels\n",
    "preprocessor = Preprocessing(h_features, h_labels)\n",
    "preprocessor.preprocess()\n",
    "labels_handcrafted, features_handcrafted = preprocessor.get_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_handcrafted, labels_handcrafted[\"class\"], test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a25878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train SVM\n",
    "svm_model = SVC(kernel='rbf', C=1, gamma='scale')\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcf2a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Evaluate\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e877e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab9049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8150b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b381737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed773f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3694d7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e718fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e2287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf007f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b284c460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c8d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c90d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b019d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c423faca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82b3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f349d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e592b20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdd000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb326a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd9668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd51d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e121f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef8494c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
